{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers in PyTorch\n",
    "\n",
    "\n",
    "##### Necessary preprocessing\n",
    "- Images must be of same size\n",
    "- Normalisation\n",
    "- Tensor datatype!\n",
    "\n",
    "To create a convolutional layer in PyTorch: \n",
    "\n",
    "\n",
    "``` torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True) ```\n",
    "\n",
    "<br />\n",
    "\n",
    "Similary, 1D Conv: ```torch.n.Conv1d```\n",
    "3DConv: ```torch.nn.Conv3d```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, there is a two part process to defining a convolutional layer and defining the feedforward behavior of a model (how an input moves through the layers of a network). \n",
    "<br />\n",
    "Define a Model class and fill in two functions.\n",
    "\n",
    "```init```  function to define the the convolutional operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrithviNet(nn.Module):\n",
    "    def __init__():\n",
    "        \n",
    "        ### Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)\n",
    "        \n",
    "        \n",
    "        ### Pooling layer\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward():\n",
    "        \n",
    "        #### forwaring conv1 layer\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        ### pooling layer\n",
    "        x = self.pool(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)```\n",
    " \n",
    " ```in_channels``` :  The number of inputs (in depth), 3 for an RGB image, for example. <br />\n",
    "```out_channels``` - The number of output channels, i.e. the number of filtered \"images\" a convolutional layer is made of or the number of unique, convolutional kernels that will be applied to an input. <br />\n",
    "```kernel_size```- Number specifying both the height and width of the (square) convolutional kernel. <br />\n",
    "\n",
    "\n",
    "```stride``` - The stride of the convolution. If you don't specify anything, stride is set to 1. <br />\n",
    "```padding``` - The border of 0's around an input array. If you don't specify anything, padding is set to 0.\n",
    "\n",
    "####  It is possible to represent both ```kernel_size``` and ```stride``` as either a ```number``` or a``` tuple```.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula: Shape of a Convolutional Layer\n",
    "\n",
    "The shape of a convolutional layer depends on the supplied values of kernel_size, input_shape, padding, and stride. Let's define a few variables:\n",
    "\n",
    "    K - the number of filters in the convolutional layer\n",
    "    F - the height and width of the convolutional filters\n",
    "    S - the stride of the convolution\n",
    "    P - the padding\n",
    "    W_in - the width/height (square) of the previous layer\n",
    "\n",
    "Notice that ```K = out_channels```, ```F = kernel_size```, and ```S = stride```. Likewise, ``W_in`` is the first and second value of the ``input_shape`` tuple.\n",
    "\n",
    "The depth of the convolutional layer will always equal the number of filters ``K``.\n",
    "\n",
    "The spatial dimensions of a convolutional layer can be calculated as: ```(W_inâˆ’F+2P)/S+1```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reducing the feature space\n",
    "- By half: ```torch.nn.MaxPool(any, 2)``` \n",
    "- By fourth: ```torch.nn.MaxPool(any, 4)```\n",
    "where ```any```  : is the size of kernel\n",
    "and ```2``` and ```4``` represents the stride."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing individual element\n",
    "\n",
    "In PyTorch data is streamlined, so we can use ``iter()`` for individual mini-batches accessing each of this data.\n",
    " \n",
    " ``next()`` makes it easy to access individual element from ``iter()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
