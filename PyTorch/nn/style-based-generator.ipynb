{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### thanks to https://github.com/SiskonEmilia/StyleGAN-PyTorch/blob/master/SGAN.ipynb\n",
    "\n",
    "# Constraints\n",
    "# Input: [batch_size, in_channels, height, width]\n",
    "\n",
    "# Scaled weight - He initialization\n",
    "# \"explicitly scale the weights at runtime\"\n",
    "class ScaleW:\n",
    "    '''\n",
    "    Constructor: name - name of attribute to be scaled\n",
    "    '''\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def scale(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "        \n",
    "        return weight * math.sqrt(2 / fan_in)\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        '''\n",
    "        Apply runtime scaling to specific module\n",
    "        '''\n",
    "        hook = ScaleW(name)\n",
    "        weight = getattr(module, name)\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        del module._parameters[name]\n",
    "        module.register_forward_pre_hook(hook)\n",
    "    \n",
    "    def __call__(self, module, whatever):\n",
    "        weight = self.scale(module)\n",
    "        setattr(module, self.name, weight)\n",
    "\n",
    "# Quick apply for scaled weight\n",
    "def quick_scale(module, name='weight'):\n",
    "    ScaleW.apply(module, name)\n",
    "    return module\n",
    "\n",
    "\n",
    "# Uniformly set the hyperparameters of Linears\n",
    "# \"We initialize all weights of the convolutional, fully-connected, and affine transform layers using N(0, 1)\"\n",
    "# 5/13: Apply scaled weights\n",
    "class SLinear(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(dim_in, dim_out)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "        \n",
    "        self.linear = quick_scale(linear)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"learned affine transform\" A\n",
    "class FC_A(nn.Module):\n",
    "    '''\n",
    "    Learned affine transform A, this module is used to transform\n",
    "    midiate vector w into a style vector\n",
    "    '''\n",
    "    def __init__(self, dim_latent, n_channel):\n",
    "        super().__init__()\n",
    "        self.transform = SLinear(dim_latent, n_channel * 2)\n",
    "        # \"the biases associated with ys that we initialize to one\"\n",
    "        self.transform.linear.bias.data[:n_channel] = 1\n",
    "        self.transform.linear.bias.data[n_channel:] = 0\n",
    "\n",
    "    def forward(self, w):\n",
    "        # Gain scale factor and bias with:\n",
    "        style = self.transform(w).unsqueeze(2).unsqueeze(3)\n",
    "        return style\n",
    "    \n",
    "    # AdaIn (AdaptiveInstanceNorm)\n",
    "class AdaIn(nn.Module):\n",
    "    '''\n",
    "    adaptive instance normalization\n",
    "    '''\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.norm = nn.InstanceNorm2d(n_channel)\n",
    "        \n",
    "    def forward(self, image, style):\n",
    "        factor, bias = style.chunk(2, 1)\n",
    "        result = self.norm(image)\n",
    "        result = result * factor + bias  \n",
    "        return result\n",
    "\n",
    "# \"learned per-channel scaling factors\" B\n",
    "# 5/13: Debug - tensor -> nn.Parameter\n",
    "class Scale_B(nn.Module):\n",
    "    '''\n",
    "    Learned per-channel scale factor, used to scale the noise\n",
    "    '''\n",
    "    def __init__(self, n_channel):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.zeros((1, n_channel, 1, 1)))\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        result = noise * self.weight\n",
    "        return result \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
